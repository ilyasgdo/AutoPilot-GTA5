# ğŸ“‹ Plan de DÃ©veloppement - AutoPilot-GTA5

> Guide dÃ©taillÃ© pour l'implÃ©mentation du systÃ¨me de conduite autonome dans GTA V

---

## ğŸ”¹ Phase 1 â€“ Pipeline de capture & vision

### 1.1 - ğŸ¥ Capture vidÃ©o GTA V

**ğŸ“Œ Objectif :** extraire les frames du jeu GTA V en temps rÃ©el

**âœ… MÃ©thodes possibles :**
- `pyautogui.screenshot()` ou `mss` pour capturer l'Ã©cran
- Utiliser **OBS** + `imageio` si besoin de performance optimale

**ğŸ“ Fichier :** `capture/screen_capture.py`

```python
import pyautogui
import numpy as np
import cv2

def get_frame():
    """Capture une frame de GTA V et la redimensionne"""
    img = pyautogui.screenshot(region=(0, 0, 1280, 720))
    frame = np.array(img)
    frame = cv2.resize(frame, (224, 224))
    return frame
```

### 1.2 - ğŸ‘ï¸ Traitement OpenCV

**ğŸ“Œ Objectif :** dÃ©tecter lignes blanches, feux rouges, panneaux

**ğŸ”§ Algorithmes :**
- Filtrage de couleur (HSV) pour lignes et feux
- **Canny** + **HoughLinesP** pour dÃ©tection de lignes
- Contours / Masques pour feux de circulation

**ğŸ“ Fichier :** `perception/lane_detection.py`

### 1.3 - ğŸ“¦ IntÃ©gration YOLOv8

**ğŸ“Œ Objectif :** dÃ©tecter voitures, piÃ©tons, feux rouges, stops

**ğŸ¯ ImplÃ©mentation :**
- Utiliser le modÃ¨le `yolov8n.pt` (rapide pour test)
- Retourner une liste de classes dÃ©tectÃ©es + positions

**ğŸ“ Fichier :** `perception/detector.py`

---

## ğŸ”¹ Phase 2 â€“ Fonction de rÃ©compense

### 2.1 - âš–ï¸ DÃ©finir la logique de rÃ©compense

**ğŸ¯ SystÃ¨me de points :**

| Action | RÃ©compense |
|--------|------------|
| Franchissement de ligne | **-5** |
| Collision dÃ©tectÃ©e (via YOLO) | **-10** |
| Griller un feu rouge / stop | **-20** |
| Avancer sans erreur | **+0.01** |
| DÃ©passement rÃ©ussi | **+5** |
| Atteindre un checkpoint | **+15** |

**ğŸ“ Fichier :** `utils/reward_function.py`

---

## ğŸ”¹ Phase 3 â€“ ModÃ¨le CNN + LSTM

### 3.1 - ğŸ§  Feature extractor CNN

**ğŸ—ï¸ Architecture :**
- **ResNet18** sans la derniÃ¨re couche FC
- Sortie : `(batch, seq_len, 512)`

### 3.2 - â±ï¸ LSTM pour mÃ©moire temporelle

**ğŸ”„ Configuration :**
- LSTM input : `(seq_len, batch, 512)`
- Output : dernier Ã©tat â†’ action

**ğŸ“ Fichier :** `rl/model.py`

---

## ğŸ”¹ Phase 4 â€“ Replay Buffer SÃ©quentiel

### 4.1 - ğŸ§© Buffer temporel

**ğŸ’¾ Structure :**
- Stocker **N frames** par transition
- Chaque transition = `(frames[], action, reward, done)`

**ğŸ“ Fichier :** `rl/replay_buffer.py`

---

## ğŸ”¹ Phase 5 â€“ Agent SAC

### 5.1 - ğŸ¤– Agent de Reinforcement Learning

**ğŸ›ï¸ Composants :**
- **Policy** = CNN + LSTM â†’ MLP
- **2 Critiques** Q1 et Q2
- **Alpha** auto-ajustÃ©
- **Target update** (polyak average)

**ğŸ“ Fichiers :** `rl/sac.py` et `rl/agent.py`

> ğŸ’¡ **Option :** partir d'un fork de **Stable-Baselines3** ou implÃ©menter SAC from scratch

---

## ğŸ”¹ Phase 6 â€“ Boucle d'entraÃ®nement

### 6.1 - ğŸ”„ Training loop principal

```python
while not done:
    # Capture et traitement
    frame = get_frame()
    infos = process_frame_with_yolo_opencv(frame)
    reward = compute_reward(infos)
    
    # Stockage dans buffer
    buffer.add(sequence, action, reward, done)
    
    # EntraÃ®nement pÃ©riodique
    if timestep % update_freq == 0:
        agent.train(buffer.sample())
    
    # PrÃ©diction et action
    act = agent.predict_action(sequence)
    send_action_to_gta(act)
```

**ğŸ“ Fichier :** `train.py`

---

## ğŸ”¹ Phase 7 â€“ Sauvegarde & Test

### 7.1 - ğŸ’¾ Sauvegarde du modÃ¨le

**ğŸ”„ FrÃ©quence :** enregistrer tous les X steps en `.pt` (PyTorch)

```python
torch.save(model.state_dict(), "models/policy.pt")
```

### 7.2 - ğŸ§ª Script de test

**ğŸ® FonctionnalitÃ©s :**
- Charger le modÃ¨le entraÃ®nÃ©
- Tourner GTA en mode "demo"
- Ã‰valuer avec rendu activÃ©

**ğŸ“ Fichier :** `test.py`

---

## ğŸ”¹ Phase 8 â€“ DÃ©ploiement RC (futur)

### 8.1 - ğŸ“¦ Export du modÃ¨le

**ğŸ”§ Formats de conversion :**
- `torch.jit.trace()` ou **ONNX** pour format embarquÃ©

### 8.2 - ğŸš— Code embarquÃ©

**ğŸ”„ Pipeline :**
1. Lire image camÃ©ra de la voiture
2. Traitement OpenCV + CNN+LSTM
3. Envoi commandes vers moteur / direction

**ğŸ–¥ï¸ Plateformes possibles :**
- **Raspberry Pi 5**
- **Jetson Nano**
- **ESP32** + co-processeur

---

## ğŸ“Š Suivi des performances

### ğŸ“ˆ IntÃ©gration Tensorboard

**ğŸ“‹ MÃ©triques Ã  suivre :**
- **Reward total** par Ã©pisode
- **Loss policy / critic**
- **Score moyen** sur N Ã©pisodes
- **Temps de convergence**

---

## ğŸ—‚ï¸ Structure finale du projet

```
AutoPilot-GTA5/
â”œâ”€â”€ capture/
â”‚   â””â”€â”€ screen_capture.py
â”œâ”€â”€ perception/
â”‚   â”œâ”€â”€ lane_detection.py
â”‚   â””â”€â”€ detector.py
â”œâ”€â”€ rl/
â”‚   â”œâ”€â”€ model.py
â”‚   â”œâ”€â”€ replay_buffer.py
â”‚   â”œâ”€â”€ sac.py
â”‚   â””â”€â”€ agent.py
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ reward_function.py
â”œâ”€â”€ models/                 # ModÃ¨les sauvegardÃ©s
â”œâ”€â”€ logs/                   # Logs Tensorboard
â”œâ”€â”€ train.py
â”œâ”€â”€ test.py
â”œâ”€â”€ config.yaml
â””â”€â”€ requirements.txt
```

---

## ğŸš€ Ordre d'implÃ©mentation recommandÃ©

1. **Phase 1** : Capture + OpenCV + YOLO
2. **Phase 2** : Fonction de rÃ©compense
3. **Phase 3** : ModÃ¨le CNN+LSTM
4. **Phase 4** : Replay Buffer
5. **Phase 5** : Agent SAC
6. **Phase 6** : Boucle d'entraÃ®nement
7. **Phase 7** : Test et sauvegarde
8. **Phase 8** : DÃ©ploiement (optionnel)

---

**ğŸ¯ Objectif final :** Un agent capable de conduire de maniÃ¨re autonome dans GTA V en respectant le code de la route, avec possibilitÃ© de transfert vers une voiture RC rÃ©elle.